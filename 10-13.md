> Suppose we can't change the cache (you usually
> can't). But you can change the code. Rewrite the
> code to achieve at least a 75% hit rate and still do
> the same work.
> One caveat, your code has to retain
> the statement:

```C
for(int i = 0; i < 2; i++)
    for(int j = 0; j < 4; j++)
        sum += A[j] - B[j]
```

will be modified to

```C
for(int i = 0; i < 4; i++)
    for(int j = 0; j < 2; j++)
        sum += A[j] - B[j]
```

Code Revision 3
A and B are int (4 byte) arrays with 2 elements

## Miss Types - Conflict

• Why do you miss on A[1]?

- conflict miss: although you had room in your cache to hold
  both `A[0-1] and B[0-1]`, the indexing caused you to get a miss
- Analogy: collisions in a hash table (your index is your hash
  function)

## Set Associative Caches

- Offer a performance middle-ground between Direct
  Mapped and Fully Associative
  - Decent hit times
  - Decent use of cache space
- As a result, their hit rates are generally higher than
  Direct Mapped

## LRU and LRU alternatives

To do LRU, you need to know the true ordering of
accesses. This means:

- Log N bits per block to store the order.
  - E.g. For a 4 way SA cache, you need to know which was accessed most recently (11), second most recently (10), second least recently (01), and
    least recently (00)
- All bits per set are updated on every access (hit or miss)
  - Led to LRU alternatives
- NMRU, LFU, LFRU, LFUDA, etc.
- Bottom line, there are ideas out there to capture how much a
  block gets used, to update fewer blocks, and to evict less used blocks

## Computing index bits, block offset bits, etc.

With n-way associative caches

```
#block_offset_bits = log2(block_size)

#entries = cache_size / ( block_size * n)
#index bits = log_2 (#entries)

#tag_bits = address_size - #index_bits -
#block_offset_bits
```

## Compulsory three types of cache misses

Compulsory (or cold-start) misses
– first access to the data.
• Capacity misses
– we missed only because the cache isn’t big enough.
– Defn: The address has already been requested AND a fully
associative cache of the same size would also experience a
miss

• Conflict misses
– we missed because of the indexing scheme/addresses caused
one block to evict another earlier than one might hope
– Defn: The address has already been requested AND a fully
associative cache of the same size would experience a hit
Summary:
