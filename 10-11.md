# Cache Basics

Processor vs Memory Performance

- Memory is very slow compared to processors

## Memory Locality

- Memory hierarchies take advantage of memory locality.
- Memory locality is the principle that future memory
  accesses are near past accesses.
- Memories take advantage of two types of locality
  - -- near in time => we will often access the
    same data again very soon
  - -- near in space/distance => our next access is
    often very close to our last access (or recent accesses).

SRAM:

- Read and write times
  - 10-100s of ps
- Bandwidth
  - Registers -- 324GB/s
  - L1 cache -- 128GB/s

DRAM:

- Read and write times
  - 60-120ns
- Bandwidth
  - Mem -- 16GB/s

## Caching Issues

On a memory access -

- How do I know if this is a hit or miss?

On a cache miss -

- where to put the new data?
- what data to throw out?
  - Typically select the Least Recently Used
- how to remember what data this is?

> tag, index block

## Miss Types- Capacity

- Why do you miss on A[0] on the first access?
  - compulsory miss.
- Why do you miss on A[0] on the second access? - capacity miss, no matter how well you try to store 4 items
  (using a least recently used replacement policy), if you only
  have room for 2, you're going to be out of space
